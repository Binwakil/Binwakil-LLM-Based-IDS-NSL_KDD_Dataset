{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "APleZbclR6WQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hwo8WBagR6WQ"
      },
      "outputs": [],
      "source": [
        "# Define column names\n",
        "c_names = [\n",
        "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
        "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
        "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
        "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
        "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
        "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"labels\", \"difficulty_degree\"\n",
        "]\n",
        "\n",
        "# Load datasets\n",
        "train = pd.read_csv(\"KDDTrain+.txt\", names=c_names)\n",
        "test = pd.read_csv(\"KDDTest+.txt\", names=c_names)\n",
        "\n",
        "# Drop irrelevant column\n",
        "train.drop(\"difficulty_degree\", axis=1, inplace=True)\n",
        "test.drop(\"difficulty_degree\", axis=1, inplace=True)\n",
        "\n",
        "# Convert categorical features to numerical\n",
        "categorical_features = [\"protocol_type\", \"service\", \"flag\"]\n",
        "for col in categorical_features:\n",
        "    train[col] = train[col].astype(\"category\").cat.codes\n",
        "    test[col] = test[col].astype(\"category\").cat.codes\n",
        "\n",
        "# Convert labels to binary (1 = normal, 0 = attack)\n",
        "train[\"labels\"] = train[\"labels\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
        "test[\"labels\"] = test[\"labels\"].apply(lambda x: 1 if x == \"normal\" else 0)\n",
        "\n",
        "# Split features and labels\n",
        "X_train = train.drop(\"labels\", axis=1)\n",
        "y_train = train[\"labels\"]\n",
        "X_test = test.drop(\"labels\", axis=1)\n",
        "y_test = test[\"labels\"]\n",
        "\n",
        "# Normalize numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert each row into a text sequence\n",
        "train_sequences = [\" \".join(map(str, row)) for row in X_train]\n",
        "test_sequences = [\" \".join(map(str, row)) for row in X_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugwjUDssR6WR",
        "outputId": "7c560bec-cbfa-4933-816f-f2d9f75a8974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load Bloom tokenizer\n",
        "model_name = \"bigscience/bloom-560m\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize data\n",
        "train_encodings = tokenizer(train_sequences, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(test_sequences, truncation=True, padding=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "# Convert labels to tensors\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = torch.utils.data.TensorDataset(train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"], y_train)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_encodings[\"input_ids\"], test_encodings[\"attention_mask\"], y_test)\n",
        "\n",
        "# Create dataloaders\n",
        "batch_size = 8  # Reduced for memory efficiency\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FoEc7l3fR6WR"
      },
      "outputs": [],
      "source": [
        "# Load smaller Bloom model\n",
        "bloom_model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Enable memory optimizations\n",
        "bloom_model.gradient_checkpointing_enable()\n",
        "bloom_model.to(torch.float16)  # Mixed-precision training for lower memory usage\n",
        "\n",
        "# Define a classification model\n",
        "class BloomIDSModel(nn.Module):\n",
        "    def __init__(self, bloom_model):\n",
        "        super(BloomIDSModel, self).__init__()\n",
        "        self.bloom = bloom_model\n",
        "        self.fc = nn.Linear(1024, 2)  # Adjusted for smaller Bloom model\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():  # Disable gradient calculation for Bloom backbone\n",
        "            outputs = self.bloom(input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0, :]  # Extract CLS token\n",
        "        return self.fc(pooled_output)\n",
        "\n",
        "# Initialize model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BloomIDSModel(bloom_model).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIE5aPnyR6WR",
        "outputId": "696fd1fa-2d9c-44c8-b538-b090a14f91ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-de5039c26e96>:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "<ipython-input-5-de5039c26e96>:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 11521.8265, Train Accuracy: 0.5124\n"
          ]
        }
      ],
      "source": [
        "# Clear GPU memory before training\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3e-5)\n",
        "\n",
        "# Enable automatic mixed precision (AMP) to reduce memory usage\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for input_ids, attention_mask, labels in train_loader:\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():  # Enable mixed precision\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    train_acc = correct / len(train_dataset)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDg6CFZJR6WR"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input_ids, attention_mask, labels in test_loader:\n",
        "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions = outputs.argmax(1)\n",
        "\n",
        "        y_pred.extend(predictions.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute accuracy\n",
        "test_acc = np.mean(np.array(y_pred) == np.array(y_true))\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Attack\", \"Normal\"], yticklabels=[\"Attack\", \"Normal\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.savefig(\"Bloom_Confusion-Matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Attack\", \"Normal\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yM3dYLTR6WR"
      },
      "outputs": [],
      "source": [
        "# Generate predictions\n",
        "y_pred = tf.argmax(model.predict(test_dataset).logits, axis=1).numpy()\n",
        "\n",
        "# Compute Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Attack\", \"Normal\"], yticklabels=[\"Attack\", \"Normal\"])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.savefig(\"Bloom_Confusion-Matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_test, y_pred, target_names=[\"Attack\", \"Normal\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DHAeJ4WR6WR"
      },
      "outputs": [],
      "source": [
        "# Compute ROC Curve\n",
        "y_pred_proba = tf.nn.softmax(model.predict(test_dataset).logits)[:, 1].numpy()\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC Curve\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
        "plt.title(\"Receiver Operating Characteristic\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig(\"Bloom_ROC-Curve.png\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BQUb5v0R6WS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}